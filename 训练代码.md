模型保存的文件后缀是 .pth

CIARF10模型为例子

CIARF10 10分类 模型

所以输出结果是一个矩阵一个tensor其中它的shape是你的(batch_size,10)这样的结果

假设你的batch_size = 1
那么你得到的结果应该是[[1,2,3,4,5,6,7,8,9,10]]这种类型的。你的输入的标签是这样的[ 9 ]



batch_size:即一次训练所抓取的数据样本数量；

batch_size的大小影响训练速度和模型优化,其大小同样影响每一epoch训练模型次数。



若BATCH_SIZE=m(训练集样本数量);相当于直接抓取整个数据集，训练时间长，但梯度准确。但不适用于大样本训练，比如IMAGENET。只适用于小样本训练，但小样本训练一般会导致**过拟合**[[1\]](https://zhuanlan.zhihu.com/p/133864576#ref_1)现象，因此不建议如此设置。

若BATCH_SIZE=1;梯度变化波动大，网络不容易收敛。

若BATCH_SIZE设置合适，梯度会变准确。

此时再增加BATCH_SIZE大小，梯度也不会变得更准确。

同时为了达到更高的训练网络精度，应该增大epoch，使训练时间变长。



当一个完整的数据集通过了神经网络一次并且返回了一次，这个过程称为一次>epoch。（也就是说，所有训练样本在神经网络中都 进行了一次正向传播 和一次反向传播 ）

再通俗一点，一个Epoch就是将所有训练样本训练一次的过程。

然而，当一个Epoch的样本（也就是所有的训练样本）数量可能太过庞大（对于计算机而言），就需要把它分成多个小块，也就是就是分成多个Batch 来进行训练。

随着epoch数量增加，神经网络中的权重的更新次数也在增加，曲线从欠拟合变得过拟合。



- **Batch（批 / 一批样本）：**

将整个训练样本分成若干个Batch。

- **Batch_Size（批大小）：**

每批样本的大小。

- **Iteration（一次迭代）：**

训练一个Batch就是一次Iteration



CPU 上训练代码

```python

import torchvision
from torch import nn
import torch
from torch.utils.data import DataLoader
from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential, CrossEntropyLoss
from torchvision import transforms
from torch.utils.tensorboard import SummaryWriter

trans = transforms.Compose([transforms.ToTensor()])
#获取训练集
dataset = torchvision.datasets.CIFAR10(root="./dataset",train=True,transform=trans,download=True)
dataset2 = torchvision.datasets.CIFAR10(root="./dataset",train=False,transform=trans,download=True)
train_dataloader = DataLoader(dataset,batch_size=64)
test_dataloader = DataLoader(dataset2,batch_size=64)

test_len = len(dataset2)

class MyModule(nn.Module):

    def __init__(self):
        super().__init__()

        self.model = Sequential(
            Conv2d(3, 32, kernel_size=(5, 5), padding=2),
            MaxPool2d(2),
            Conv2d(32, 32, (5, 5), padding=2),
            MaxPool2d(2),
            Conv2d(32, 64, (5, 5), padding=2),
            MaxPool2d(2),
            Flatten(),
            Linear(1024, 64),
            Linear(64, 10)

        )


    def forward(self,x):
        x = self.model(x)

        return x


if __name__ == '__main__':
    writer = SummaryWriter()
    mymodule = MyModule()
    loss = torch.nn.CrossEntropyLoss()
    learnstep = 0.01
    optim = torch.optim.SGD(mymodule.parameters(),lr=learnstep)
    epoch = 1000

    train_step = 0 #每轮训练的次数
    mymodule.train()#模型在训练状态
    for i in range(epoch):
        print("第{}轮训练".format(i+1))
        train_step = 0
        for data in train_dataloader:
            imgs,targets = data
            outputs = mymodule(imgs)
            result_loss = loss(outputs,targets)
            optim.zero_grad()
            result_loss.backward()
            optim.step()

            train_step+=1
            if(train_step%100==0):

                print("第{}轮的第{}次训练的loss:{}".format((i+1),train_step,result_loss.item()))

        # 在测试集上面的效果
        mymodule.eval() #在验证状态
        test_total_loss = 0
        right_number = 0
        with torch.no_grad(): # 验证的部分，不是训练所以不要带入梯度
            for test_data  in test_dataloader:
                imgs,label = test_data
                outputs_ = mymodule(imgs)

                test_result_loss=loss(outputs_,label)

                right_number += (outputs_.argmax(1)==label).sum()

            # writer.add_scalar("在测试集上的准确率",(right_number/test_len),(i+1))
            print("第{}轮训练在测试集上的准确率为{}".format((i+1),(right_number/test_len)))

        if((i+1)%500==0):
            # 保存模型
            torch.save(mymodule.state_dict(),"mymodule_{}.pth".format((i+1)))

```



GPU上训练

```python


import torchvision
from torch import nn
import torch
from torch.utils.data import DataLoader
from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential, CrossEntropyLoss
from torchvision import transforms
from torch.utils.tensorboard import SummaryWriter

trans = transforms.Compose([transforms.ToTensor()])
#获取训练集
dataset = torchvision.datasets.CIFAR10(root="./dataset",train=True,transform=trans,download=True)
dataset2 = torchvision.datasets.CIFAR10(root="./dataset",train=False,transform=trans,download=True)
train_dataloader = DataLoader(dataset,batch_size=64)
test_dataloader = DataLoader(dataset2,batch_size=64)

test_len = len(dataset2)
if(torch.cuda.is_available()):
    device = torch.device("cuda")
    print("使用GPU训练中：{}".format(torch.cuda.get_device_name()))
else:
    device = torch.device("cpu")
    print("使用CPU训练")
class MyModule(nn.Module):

    def __init__(self):
        super().__init__()

        self.model = Sequential(
            Conv2d(3, 32, kernel_size=(5, 5), padding=2),
            MaxPool2d(2),
            Conv2d(32, 32, (5, 5), padding=2),
            MaxPool2d(2),
            Conv2d(32, 64, (5, 5), padding=2),
            MaxPool2d(2),
            Flatten(),
            Linear(1024, 64),
            Linear(64, 10)

        )


    def forward(self,x):
        x = self.model(x)

        return x


if __name__ == '__main__':
    writer = SummaryWriter()
    mymodule = MyModule()
    mymodule = mymodule.to(device) #模型转移GPU
    loss = torch.nn.CrossEntropyLoss()
    learnstep = 0.01
    optim = torch.optim.SGD(mymodule.parameters(),lr=learnstep)
    epoch = 1000

    train_step = 0 #每轮训练的次数
    mymodule.train()#模型在训练状态
    for i in range(epoch):
        print("第{}轮训练".format(i+1))
        train_step = 0
        for data in train_dataloader:
            imgs,targets = data

            imgs = imgs.to(device)
            targets =targets.to(device)

            outputs = mymodule(imgs)
            result_loss = loss(outputs,targets)
            optim.zero_grad()
            result_loss.backward()
            optim.step()

            train_step+=1
            if(train_step%100==0):

                print("第{}轮的第{}次训练的loss:{}".format((i+1),train_step,result_loss.item()))

        # 在测试集上面的效果
        mymodule.eval() #在验证状态
        test_total_loss = 0
        right_number = 0
        with torch.no_grad(): # 验证的部分，不是训练所以不要带入梯度
            for test_data  in test_dataloader:
                imgs,label = test_data

                imgs = imgs.to(device)
                label = label.to(device)

                outputs_ = mymodule(imgs)

                test_result_loss=loss(outputs_,label)

                right_number += (outputs_.argmax(1)==label).sum()

            # writer.add_scalar("在测试集上的准确率",(right_number/test_len),(i+1))
            print("第{}轮训练在测试集上的准确率为{}".format((i+1),(right_number/test_len)))

        if((i+1)%500==0):
            # 保存模型
            torch.save(mymodule.state_dict(),"mymodule_{}.pth".format((i+1)))

```



