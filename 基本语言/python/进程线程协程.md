相关概念：进程、线程、协程、锁、GIL 

https://www.cnblogs.com/aylin/p/5601969.html

进程：就是我们ps aux出来的，一个进程就是一个程序，它是由操作系统管理的，一个进程可以派生另一个进行，比如：执行bash命令；进程之间是闭塞的，无法简便的共享数据，这时候就出来了线程

线程：也叫【轻量级进程】，同一个进程下开启多个线程，这些线程时属于这个进程的，当进程退出时，线程也会强制退出；这些多线程共享进程的资源，而这些多线程由于是在一个进程下的，所以就能很好的共享数据，但是也导致了一个问题就是同一资源被多个线程更改导致出错，这个问题的避免方法是【线程锁】，即：threading.Lock()，在进行一个资源的“原子性”（这个名词时我从Mysql的事务中借来的名词）操作时，就把再这个操作开始前上一个锁，执行完成之后释放这个锁，这样别的线程在上锁之后就没法更改这个资源，只有等资源释放后才能继续获取这个资源；线程池的概念是由于每次创建线程、销毁线程都需要耗资源，就有了线程池的概念，这个池子中一直启动着几个线程，每次调用这个池子里的线程

协程：更小单位的线程

GIL：GIL全局解释器锁：由于这个GIL的存在，python其实没法实现真正意义上的多进程？还是多线程？为什么来着？



进程：

```
multiprocessing
```



线程：

```python
from threading import threads

def test_multi_thread(self):
    start = time.time()
    threads = []
    for url in self.urls:
        threads.append(threading.Thread(target=blog_craw, args=(url,)))

    for thread in threads:
        thread.start()

    for thread in threads:
        # thread 线程调用了 join() 方法，并且没有指定具体的 timeout 参数值。
        # 这意味着如果程序想继续往下执行，必须先执行完 thread 线程
        thread.join()
    end = time.time()
    # 0.6
    print('single thread cast:', str(end - start))
    
def blog_craw(url):
    re = requests.get(url)
    print(len(re.text))
```



queue:用于多线程通信

先进先出队列模式

queue.put()：放到队尾

queue.get()：取队首

类似于【生产者-消费者】模式

quene能保证线程安全

为什么能保证呢？因为他们是有顺序的？

```python
import queue
import time
import random
import threading
import requests
from bs4 import BeautifulSoup

urls = [f'https://www.cnblogs.com/pick/#p{i}' for i in range(2, 20)]


# 生产者
def blog_craw(url):
    re = requests.get(url)
    return re.text


# 消费者
def blog_parse(html):
    soup = BeautifulSoup(html, 'html.parser')
    links = soup.find_all('a', class_='post-item-title')
    return [(link['href'], link.get_text()) for link in links]


# 包装函数
def do_craw(url_queue: queue.Queue, html_queue: queue.Queue):
    while True:
        url = url_queue.get()
        html = blog_craw(url)
        html_queue.put(html)
        print(
            threading.current_thread().name,
            f'craw {url}',
            'url_queue.size:',url_queue.qsize()
        )
        time.sleep(random.randint(1,2))


def do_parse(html_queue: queue.Queue, filestd):
    while True:
        html = html_queue.get()
        results = blog_parse(html)
        for result in results:
            filestd.write(str(result) + '\n')
        print(
            threading.current_thread().name,
            'resule size:', len(results),
            'html_queue.size:', html_queue.qsize(),

        )
        time.sleep(random.randint(1,2))


if __name__ == '__main__':
    url_queue = queue.Queue()
    html_queue = queue.Queue()
    for url in urls:
        url_queue.put(url)

    for idx in range(3):
        t = threading.Thread(target=do_craw, args=(url_queue,html_queue),name=f'craw{idx}')
        t.start()

    filestd = open('queue_data.txt', 'w')

    for idx in range(2):
        t = threading.Thread(target=do_parse,args=(html_queue,filestd),name=f'parse{idx}')
        t.start()
```

锁：保证线程建数据的正确性：

```python
import threading
import time

lock = threading.Lock()

class Account:
    def __init__(self, balance):
        self.balance = balance

def draw(account,num):
    with lock:
        if account.balance >= num:
            time.sleep(0.1)
            print('余额充足')
            account.balance -= num
            print('余额为：:',str(account.balance))
        else:
            print('余额不足')
            print('余额为：:', str(account.balance))


if __name__=='__main__':
    account = Account(1000)
    td1 = threading.Thread(target=draw, args=(account,800))
    td2 = threading.Thread(target=draw, args=(account,800))

    td1.start()
    td2.start()
```

线程池：

```python
import concurrent.futures
import requests
from bs4 import BeautifulSoup

urls = [f'https://www.cnblogs.com/pick/#p{i}' for i in range(2, 6)]


# 生产者
def blog_craw(url):
    re = requests.get(url)
    return re.text


# 消费者
def blog_parse(html):
    soup = BeautifulSoup(html, 'html.parser')
    links = soup.find_all('a', class_='post-item-title')
    return [(link['href'], link.get_text()) for link in links]


# 生产者线程池
with concurrent.futures.ThreadPoolExecutor() as pool:
  	# pool.map()的方式：把参数一起都传进去了，返回的结果和入参顺序对应
    htmls = pool.map(blog_craw, urls)
    htmls = list(zip(urls, htmls))
    for url, html in htmls:
        print(url, len(html))

print('craw over')


# 消费者线程池
with concurrent.futures.ThreadPoolExecutor() as pool:
    futures = {}
    # pool.submit()参数是一个一个的进去的
    for url, html in htmls:
        future = pool.submit(blog_parse,html)
        futures[future] = url

    # future.items()：这样是按顺序打印的
    # for future,url in futures.items():
    #     print(url, future.result())

    # concurrent.futures.as_completed()是按住完成的顺序打印的
    for future in concurrent.futures.as_completed(futures):
        url = futures[future]
        print(url, future.result())
```

面试题：

创建两个线程，其中一个输出1-52，另外一个输出A-Z。输出格式要求：12A 34B 56C 78D

```python
import threading
import time


# 获取对方的锁，运行一次后，释放自己的锁
def show1():
    for i in range(1, 52, 2):
        lock_show2.acquire()
        print('线程1')
        print(i, end='')
        print(i + 1, end='')
        time.sleep(0.2)
        lock_show1.release()


def show2():
    for i in range(26):
        lock_show1.acquire()
        print('线程2')
        print(chr(i + ord('A')))
        time.sleep(0.2)
        lock_show2.release()


lock_show1 = threading.Lock()
lock_show2 = threading.Lock()

show1_thread = threading.Thread(target=show1)
show2_thread = threading.Thread(target=show2)

lock_show1.acquire()  # 因为线程执4行顺序是无序的，保证show1()先执行

show1_thread.start()
show2_thread.start()
```

