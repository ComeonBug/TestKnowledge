上面提的就是那个4个VCA业务的开发团队，第一个是那个偏产品端的，然后第二块是其实是整个信贷的业务核心，信贷核心嘛，就是整个后端的逻辑。然后第三块是偏风控的，因为做信贷的话，它里面有很多风控的一个一些事情要做决策判断。就是决策引擎啊，这些事情叫风险平台，这是第3块，然后第4块是整个数据，就是整个离线数仓，然后BI啊，然后实时计算，这些都在那个数据团队。然后这整体所有加起来，我们现在整个字数是180多人。然后黑框是200个，大概是这样一个情况，



我叫李阳，然后是14年毕业于天津工业大学的软件工程专业，然后从毕业到现在也一直从事的是软件测试这个行业，然后先后的话，APP的功能自动化和专项，然后还有web端的功能自动化以及API和接口的。测试和。HTTP接口的一个性能测试，目前也有接触到web端的安全测试和容器的安全测试，然后这些都有过设设计。然后最近的一份工作的话是在商汤科技，它主要是做人工智能的，然后我负责的项目的话，有参加过AI工具链的一个工具，然后还有是评测工具的测试。然后还有是。就是一个|嗯。监控平台的一个测试，嗯，目前的话就这些。了解OK，



# 问题1:

我先了解一下商汤这边那个整个测试团队大概是有多少人？

我们这边的话是分不同的部门，然后就像我们这个二级部门的话，它有两个测试团队，然后分为Paas层和Iass层的测试团队，然后我们这个是IasS层，我们这边的话大概是20多人的团队。



# 问题2:

你可以介绍一下你主要负责的一个工作，就是比如说在这个领域里面，然后为了保障这个业务质量，背后遇到的一些主要的问题和挑战，然后你是通过什么方式去解决这些问题的？

我说一下我最近的一段时间的这个工作吧，因为我们在去年年中的时候，经历过一次组织架构的变更加上原项目的停止，然后我就接手了目前的3个项目，一个是云监控、一个云审计、还有一个是云容器安全。这3个项目都是那种需要对接很多子产品的项目，比如说监控，它需要监控所有子产品的指标，以及部分一些子产品的日志，而审计这边的话，它是对子产品的所有的操作做一个审计功能，所以它也是对接很多子产品的，而这俩项目，他们的迭代周期时完全重叠的，其实这也是我们作为测试经常去讨论的一个点，就是【测试的人力不足问题】

遇到这种问题，我的处理方式就是case by case，我们需要去分析项目的属性，找到对应的耗费人力的地方，然后针对性的将问题解决掉，然后在去分析哪里可以通过自动化的手段，来降低人力消耗，总结过来就是两点：1是解决问题来减少无意义的人力消耗，2是减少重复工作的人力消耗

比如以云监控这个项目来说，云监控它有一个问题，就是他对接的子产品非常多产品，而这些子产品又又不同的采集的指标及采集方式，然后经常就有子产品，比如说，他说我这个指标没有了需要你云监控这边来排查，但是其实我们这个链路是一个很长的一个排查路径。就是指标的链路是这样子的：子产品采集、上传到中间件，中间件才传到sre管线，然后再传到监控这边的管线，再由监控的内部处理逻辑处理后再返回给子产品，所以这个连路上看，起码涉及到4方了，单子产品一般就直接找到云监控这里，需要云监控来做一些列的排查，我在经过1个月的一个实际的调研后发现，其实真正属于云监控的bug是很少的，反而很多是子产品侧自己的问题，比如说他们指标的输出有变化了，或者是前端页面有变化，没有成功显示出来我们返回的指标数据，或者是中间件的label变化了，导致指标虽然进入了系统，但是由于label的变化导致无法match，等等一系列的问题

所以我就根据这个指标采集的整个链路，写了详细的问题排查手册给到子产品，其中说明，每一步在哪个系统里查，查什么东西，如果查出来的结果是A那是谁的问题，应该找谁，如果是B则继续下面的排查步骤，一些列排查步骤结束后，首先是这个过程过滤掉了很多不属于监控的bug，原来比如3个子产品都有问题需要排查，那我在这上面耗费的时间可能是1h，但是现在我这1小时就能节省下来，而且对于子产品来说，其实他们各自耗费的时间是可以接受的，毕竟他们排查一个问题大概只需要十几分钟而已，以及，他们可以把控这个bug的进展，不需要依赖于别的系统，一直去push别人，所以他们也是很高兴能有这样一个排查手册给到他们的

这样，到时候踢到我这里的bug就基本能确定是监控侧的bug，而且子产品还会顺便提供排查的过程结果，也帮我节省了bug的排查过程，这样第一个问题就解决了



然后开始解决第二个问题，第二个问题的话，就是需要在琐碎的日常工作中，将那些重复的工作提取出来，然后将他们进行自动化

我这边对于监控和审计这俩项目进行评估后发现，由于我们产品的特性，不同的专有云客户会有需要部署不同的集群环境，而每一套环境部署后，都需要验收一次，每次验收的case都是一样的，评估后，这个是可以自动化的一个方面，以及日常的版本测试的回归测试阶段每个版本都要回归一遍，也是一个可以自动化的环节

所以，先初步定好了方向，就是要自动化这两个环节：回归和验收

然后，再去分析，因为项目的不同，其实他们适合的自动化是不同的

比如，监控项目，它主要是提供给子产品指标以及自身产品的指标告警等功能，侧重于接口，只要接口返回的数据OK，那功能大概率是OK的，所以这个项目的自动化是适合做接口自动化的

而审计这个项目来说，它由于是我们去消费mq的消息队列，然后把消息存到对象存储，用户在页面进行事件的查询、导出，它这个项目来说，接口极少，页面功能简单，且页面基本不变更，只会增加审计事件，而具体页面的展示逻辑是不变的，所以经分析，审计这个项目就适合做UI自动化



经过这样的一个分析，然后就可以去具体解决了

然后对于监控，就是设计接口自动化框架，对于审计，设计UI自动化框架



由于我这个项目来说，就我一个人负责，以及测试团队其他人的话， 也具有一定的代码水平，所以就直接采用yaml文件作为自动化测试用例的编写格式，如果团队的有一些比如外包同学他们的技术水平有限的话，或者是留给咱们自动化的时间比较充裕的话，可能在编辑自动化框架的时候需要在测试用例编写的文件或者形式上去考虑的更简单一点，比如通过excel的方式，或者是通过编写一个页面等

然后，其实在编写的这么多的框架以后，总结过来，不论是接口自动化框架，还是UI自动化框架，其实他们的本质都是一样的逻辑：就是解析我们的测试用例，然后把他们变为testcase，然后通过pytest运行，最后产出allure报告，就这一套底层的逻辑

然后具体就是在这个大的框架下去填充内容

具体来说：接口自动化 我们在多加一层接口配置层，即配置接口的url、请求方式、请求data等，这样如果后期修改了接口，直接改配置文件即可，不需要改case，因为具体的case是通过 接口配置+测试用例配置来解析出来的

然后再来说：UI自动化 我们常见的PO设计模式就是家了一层page层，其实仔细想想，和接口自动化加的那一层接口层，是不是很类似，都是抽象出来一个中间层的对象，使得 业务的修改，尽量少的改动到case，这也是我在写了这么多的框架以后的一个感悟，就是【没有什么问题是就加1层不能解决的，如果有，就加2层】

就像很多产品架构一样，加一层中间件层，很多问题就都解决了



然后我们在回到要解决的问题上，就是要解决回归和验收测试

但是，如果我们自动化跑起来了，我们肯定不愿意自动化只单单能应用在这俩方面上，所以就在自动化的设计上，增加了用例分级的这样一个想法

就是通过mark标记，标记case的级别、标记case的用途、环境等

这样到时候执行的时候只需要执行对应mark标记的case即可

最后这个框架就搭起来了，最后的收益也比较明显，我这里1个人完全可以handle住3个项目，而且验收测试由原来的2人天现在直接将为0.5人天了



# 问题3

那从你的角度看，比如说你当前的这一套，对吧，还有哪些不足呢，或者说提升空间

当然有，万物皆可自动化，只不过需要看看产出比，以及是否适合需要



然后我们有2点可以做的

1、自动化的解析swagger，将解析出来的结果自动生成测试用例

2、每日检查swagger接口变更，如果有则发邮件给测试，以及出发接口自动化构建



这2点，我在蔚来汽车当时做过，为什么没有在商汤做呢，这个还是要看研发对于swagger接口的维护程度的，在商汤这边，由于一些人力变动的关系，项目当前负责人和以前大概率不是同一批，所以swagger上有很多前端根本没有调用的接口，以及一些后端也早就不在使用的接口

这样的情况，自动解析swagger接口为用例就不太适合了，比较适合做第二个，然后我这边也是有落地方案的

这俩以前我在蔚来汽车的时候都做过

我说一下方式的一个方案设计

注意点，

如果这2点都要做的话，我当时是使用到jenkins任务：

任务1：执行一个python脚本，这个python脚本就是用来做【swagger的新旧diff】，如果有变化，则发送邮件给到测试，如果测试看到这个diff结果，确认是这次的一个变更范围，那就进行第二步，如果测试发现有需求中或者事先约定的接口文档中没有说明其中某些接口的变更，则需要和产品和研发侧确认这个变更的影响，然后等确认完再做第二步；当然如果没有差异，那就不进行下面的任务了







这个当时为什么不和后面的解析一起构成一个jenkins流水线呢？

首先是找个diff的结果目前我们是需要一个人为的进行确认环节，这个如果自动就就行了后面的接口生成，那可能会造成一些脱离测试掌控的一个事情



就是写个python小脚本：然后构建一个jenkins的构建，其中运行这个python脚本，如果

首先第一步就是获取到swagger的接口信息

这个就直接python请求swagger UI的地址，返回的html信息里去解析出来就行

然后存为新的接口信息，存到一个json或者yaml里，其中有：path、method、params、excepted status code、excepted response

然后和上一次解析道的这个json相对比，如果有变更，那就发邮件

```python
# diff脚本思路
import json
import os
from requests import request


class SwaggerPaser:
    path = os.path.abspath('.')
    def swagger_parser(self, json_data):
        new_swagger_json_data = {}
        return new_swagger_json_data


    def get_swagger(self, swagger_path):
        # 从swagger url中获取接口列表
        swagger_data = request(swagger_path)
        # 调用swagger_parser，将返回的信息解析为new swagger data的接口信息列表
        new_swagger_json_data = self.swagger_parser(swagger_data)
        # 先rename以前的信息
        os.rename(self.path + '/data/swagger/old_swagger.json', self.path + '/data/new_swagger.json')
        # 再把新的swagger存到新的
        with open(self.path + '/data/new_swagger.json') as f:
            json.dump(new_swagger_json_data,f)


    def swagger_diff(self, old_swagger_path, new_swagger_path):
        with open(old_swagger_path) as f_old:
            old_swagger_data = json.load(f_old)
        with open(new_swagger_path) as f_new:
            new_swagger_data = json.load(f_new)
        # differ = set(old_swagger_data.item()) ^ set(new_swagger_data.item())
        result_diff = ''
        result_more = ''
        result_less = ''
        for k,v in new_swagger_data.item():
            if k in old_swagger_data.key():
                if v == old_swagger_data[k]:
                    continue
                else:
                    result_diff += '接口'+ k + '原数据为' + old_swagger_data[k] + '变更为' + new_swagger_data[k] + '\n'
            else:
                result_more += '新增接口' + k + '\n'
        old_keys = old_swagger_data.keys() - new_swagger_data.keys()
        if old_keys:
            for i in old_keys:
                result_less += '减少了接口' + i + '\n'
        os.remove(self.path + '/data/email/result.txt')
        if result_diff & result_less & result_more:
            with open(self.path + '/data/email/result.txt','w') as f:
                f.write(result_diff + result_less + result_more)
```



jenkins的script中加入一句判断，

判断【'/Users/liyang/PycharmProjects/autohttptest/report/email/result.txt'】这个文件如果存在，就判断为构建失败，发email，如果不存在，就构建成功，不发email

这里的jenkins构建需要写在jenkinsfile，因为会有一些片判断

```shell
node('win_agent') {
    try {
        // 自动化测试 
        stage('Swagger Diff') {
        		script: '''python diff.py'''
            TEST_STATU = bat (
                script: '''ls -l ~/autohttptest/report/email/result.txt''',
                returnStatus: true
            ) == 0
            
            if ("${TEST_STATU}" == "false") {
                catchError(stageResult: 'FAILURE') {
                    echo "swagger存在diff"
                    env.LOG = "测试未通过"
                }
            } else {
                echo "swagger无diff"
                env.LOG = "测试通过"
            }
        }
    } catch (exc) {
    	currentBuild.result = 'FAILURE'
        echo "Something failed, I'm in the catch block."
  	} finally {
    	stage("email") {
            emailext (
                subject: '\'构建通知:${PROJECT_NAME} - Build # ${BUILD_NUMBER} - ${BUILD_STATUS}\'',
                to: "XXXXXXXX@163.com", 
                body: '${FILE,path="email.html"}',
                )
        }
  }
}
```



然后，当我们测试确认完了，目前接口的变更没有问题，符合预期，那就去手动执行一下case生成的Jenkins

任务2:case自动生成的jenkins任务

这里就是另一个python的脚本，就是我们的接口自动化case，不论源收集方式是什么，是excel，还是UI，哈还是我们的swagger，我们最后都建议先转到一个json或者yaml文件中，就也是相当于抽象出来一层数据层，然后testcase在通过parametrize来解析参数



```python
host = CaseHelper.load_host_from_config()
ids,case_list = CaseHelper.load_case_from_json("/data/get_alerts.json")

class TestGetTelemetryAlert:
  # 轮循case_list，ids和case_list对应，作为子用例执行名称
  # "case"作为形参传入
    @pytest.mark.parametrize("case", case_list, ids=ids)
    def test_get_telemetry_alert(self, case):
      	params = case['path']
        
        case_path = Paser.parse_url(path, case)
        res = requests.get(path, params=payload, headers=header)
        print(res.json())
        assert case["check"].get("code") == res.status_code
```





上面的流程其实还可以继续细化继续自动化

就是我们的diff结果，如果不符合预期，那这个diff的结果是需要丢弃的，目前这个是通过手动删除新的解析文件，这个想了下，也是需要一个简单的jenkins任务+shell脚本就可以解决

用户只要构建这个jenkins任务，就是恢复原状， shell中，clone自动化代码，进行文件的remove操作，提交代码 即可



# 问题4

你们其他团队的话，他们会做类似的这样的一些工具，就是说自动化相关的事情

因为我们团队的话，就是他的项目都完全不一样，比如说算力池那边，他的重点侧重于在跑模型，跑模型跑训练这块儿，所以他可能就是跟我的这种侧重接口



# 问题5

比如说从你的角度看，你你现在手头这个领域的吧，他测试上的难点主要在哪里

我觉得是2点：

第一点是明确如何测，比如我在给其他团队搭建模型测试自动化框架的时候，我是需要先了解这个模型是怎么测试的

第二点是技术，比如我们以前的服务都是直接部署在机房服务器上的，而现在，都是在云上，部署在容器里，这就涉及到云原生相关的知识储备，比如：微服务、devops、云容器等等，作为测试都要对这些技术有所了解；而接入新的架构以后，其实我们测试需要考虑的点也会不同，比如现在的云容器技术，可以做到资源配置的弹性伸缩，所以性能测试在这里占比不是很大，但是容量测试需要考量进来了，以及咱们的混沌工程，在云容器的环境下又该如何做



# 问题6

了解那个Python的多线程吗？python是真正的多线程吗？

thread

threadingPool

GIL锁

引申：我在做自动化想要缩短总的执行时间的时候，想过使用多线程执行case，但是事件之后出现了一些问题没法很好的解决，后来就放弃了多线程

问题有：

1、对于全局变量，可能会发生状态竞争，就是比如多个线程同时修改同一个全局变量的时候，以及可能不同的case先后修改全局变量也会导致不一样的测试结果，为了解决这个问题，可能还要引入锁的机制，但引入锁就可能导致出现死锁，引入的技术越多，外部影响越多，有时候case不通过反而不是case本身的问题，而是引入的技术的问题

2、测试可复现性低，就是我们这次跑case的顺序可以和下次的case不一样，那bug可能就无法稳定复现



# 问题7

你有你平时那个测试的时候会去看开发的代码吗？

每一次的需求，他都改了什么内容的它具体的代码我们现在是看不到的，因为它我们现在研发部署的时候，他提交的是一个K8S的一个values嘛，所以我们只能看到他更新的一个镜像，然后他已经打包好|一个镜像给到我们了，所以的话就是我们只部署的时候只只知道哪些服务有了变更。但对于具体的代码已经就是是黑盒了



# 问题8

比如说你做测试分析的时候，对吧，就是你怎么去分析它的，比如说这个需求，或者说研发的这次的设计，对。

这个主要是看它们的一个研发架构图，它的架构是什么样的，，使用的什么技术、服务之间是怎么调用的

而每个服务的一个功能是做什么的，比如需求是提供某个子产品需要增加一个指标显示

然后那我知道这个增加指标这个功能：涉及到指标的采集、处理、面板配置：

那就是分别对应：采集的otel服务、指标处理的workflow服务、指标渲染的Visualization服务

到时候提测的时候就看这3个服务有没有变更，而其他的服务有变更话的，是不是有对应的需求

# 问题9

有碰到一些漏测的case吗？

说实话我这里基本没有

因为漏测的一个本质就是：【一个你没测试到的场景在线上出现了】对吧

所以，如果只要避免情况，就是你测得到位，那基本上漏测的情况极少，即使有，我认为可能也不叫漏测，而基友可能是发布的问题、需求没有考虑到位的问题等等

而如果能保证，我测试到位了呢？

说起来就2点：很简单，【范围够广，深度够深】

但是，如何做到这两点呢？

我觉得需要自动化和人的经验来配合

自动化来保证测的范围的广度，人的经验来保证测试的深度

自动化的话：case甚至真的能达到全量覆盖

以及接入CICD流程，提高提测质量，在回归时候，进行自动化的全回归，这样过来，有漏掉的真的基本为0 

人的经验来说，就是首先是关注一些UI的东西、以及一些逻辑组合，还有就是2/8定律、错误推测法，总之一系列思考的策略来进行深度测试



# 问题10

了解OK，然后你业余时间有看一些技术方面的内容。最近最近看的容器的比较多一点，正好容器安全也属于容器整体知识体系的一部分，还和安全相关挂钩，最近就都有在看，就既能学习有能及时实践

# 问题11？

OK, 安全你们现在主要是在保障什么问题的。

我我现在这边的话主要是做容器安全，

# 问题12

比如说后面的一个发展，对吧，就未来的两年你有一个大致的规划。

从我过往的履历也能看出来，我目前是一个全面型的人，什么都负责过

我希望我的未来是一个T型人才，就是广度目前差不多了，希望能在深度方面有所钻研

我目前是希望能在自动化方面能更深入一些

因为自动化这个词，在我看来，不单单是接口自动化、UI自动化

我希望的自动化是能不手动就不手动

这里的自动化一个自动化平台，他有很多的自动化的功能；

用例自动生成、自动构建测试任务、自动提bug跟踪、自动产出分析报告、自动执行接口测试等等，而每一个说道的功能其实都有很多的可以做的事情

测试左移、测试右移、和devops结合构建CICD流程等等等

能做的事情太多了，我现在也只是做了其中的一些模块，还有很多可以做的事情可以学的地方

# 问题13：

解那个你我看你里面也带过团队的吗？你之前那个你最多带多少人，那比如说怎么去分配他的九个人的一些工作的

最多是在上上家公司，是在未来汽车，当时团队的人数大概是最多到9人吧。

对于管人来说，我个人的经验是，管理团队大概以10人为界

10人以上的团队管理是管事儿，10人以下的团队管理是管人

10人以下的团队，每个人的手头的事情，管理者还是可以管理的来的，也是达到精准的121，主要管好这个人，那这个人负责的事情基本没有问题了



10人以上，就需要考虑一些管理手段和策略，而且你没法通过管理人来达到管理整个组的目的了，人太多了

所以这时候需要的是管理事儿，事情的进展是什么样的，这个事情就可能是一个人负责，也可能是多个人负责的，那这是小组长应用而生，事儿又对到了，人，但是这时候有了小组长的角色，所以当然人还是要管的，只不过是管小组长， 这时候小组长总数也是大概小于10的，就是看目前的一些组织架构，就是老板的直系汇报管理的下属不会太多，就是这个道理

10人以下管人的时候，就是重点看人么，这个人的工作量是否OK，这个人的产出如何，这人团队协作如何，技术能力如何，考量如果成员、项目有变动如何规划，整个组织的人员划分、backup机制、知识库建立等等

10人以上事情都做的怎么样，团队产出如何，今年明年的计划是什么，目前进展如何，人才储备和团队赋能如何，内外部影响力如何等



# 问题14：

你有碰到一些难搞的case吗？难搞的case具体是人还是项目呢？

上上个项目，autolink

当时整个项目只有一个测试，她是刚毕业2年，经验不太丰富，然后经常就会被研发投诉说质量有问题。那个项目的话又是老板比较关注的一个项目，所以就需要一个经验丰富的人来负责，当时招我进去之后就是负责那个项目，那个项目。就先摸底么，项目难搞，确实质量很差，pm、产品、运营都很年轻，我、研发、老板算是经验比较丰富的

这位研发leader就算是比较难搞吧，就是那种什么事情都推诿到测试、产品甚至运营身上，

咱们就是了解了一个基本情况以后，就开始解决目前的一个最大的问题，就是质量差的问题，这里我一般方式是解决问题，而不是解决提出这个问题的人，因为对方如果难搞，那直接对上肯定是吃亏的，毕竟都说了这人【难搞】

所以我们不解决人，解决问题

因为问题是客观存在的， 这个问题存在，那我们的成果就是不好，如果问题解决了，这人难搞不难搞对我们来说不重要

所以先定心【解决问题】

解决问题，我在解决问题上，有3点：第一点【利他】，第二点【正反馈】



# 问题15：

了解OK，然后那个像比如说你你带人的时候，那个团队里面有一些比如说不好带人的。

不好带的话基本不太多，可能会有一些同学，他可能是比如说他待的时间长了，他可能会有一些懈怠，就是毕竟时间长了之后，老人嘛就是会懈怠一些

这种也可以理解，毕竟如果长时间处于一个环节中，没有竞争和危机感或者是习惯了一个环境，人多少会懈怠一点的

所以，就是可能需要找到【不好带】的原因吧

他是为社么不好带

是因为本身性格就偷奸耍滑？还是因为环境就这样没有竞争性和积极向上的氛围？还是因为自己的未来发展比较迷茫？还是因为对职场失望了？等等

对症下药就行

偷奸耍滑就可能需要和老板和HR聊，就很不幸会有一些比如项目边缘化、低绩效或者是优化名额吧，这很冷酷但是不得不做

环境的竞争意识和积极性是一定要培养起来的，咱们也不做华为那么狼性的，咱就很朴素的给予做得好的同学、积极的同学一定的表扬、升级、高绩效即可，以及对于一些普通的同学，调动他们的积极性，只要积极了，就都进入到高绩效的池子里呗，积极的话，那就是【给予重任，我看好你】，给予超出对方能力大概10%的工作，以及正反馈、表扬

迷茫的话，了解未来发展方向，以及【给予重任，我看好你】，给予超出对方能力大概10%的工作

职场失望的话，那如果能看到上面两点对于整个测试组的气势的改变的话，也是能带动的

# 问题16：

那个我顺便也了解一下那个商汤的业务现在发展怎么样。

在国内的AI领域算是top吧，它有中国目前最大的一个算力中心，英伟达它芯片卡脖子的时候，其实对手握算力的话，就是还挺关键的。

有算力的话，就很适合做模型训练，就是商汤他的模型训练是很强的，业内有很多模型购买的客户，比如一些机场的人脸、商场的人脸识别，还有一些公安系统的智慧城市系统等，然后短板可能是在业务落实，目前比较好的是：人机交互下棋机器、车载系统、云平台等，云平台的话，去年的营收是10个亿左右，就是我们团队目前所测的项目

这个系统就是用户可以去在我们云平台上购买一些资源，比如说他可以买算力池的套餐，或者是可以买云容器的套餐，就是他不需要自己有算力，不需要自己有模型，他只需在我们这个平台上购买想要的套餐或者资源即可，我们提供了算力池、云容器、存储、不同类型显卡、以及配置的监控、审计、安全、镜像管理、数据管理、标注、等等，所有涉及到训练过程的工具，都可以在我们这个平台上购买

总的来说，只要手握模型、算力，未来肯定不会差的



# 问题17：

OK，你们|因为因为你们也做那个AI，就是你们有没有公司里面有没有考虑过，像比如说像开发啦，或者测试了相关的一些事情，通过AI的方式能去自动生成或者补足的，比如说UT的自动生成之类的，就类似的事情，你你们可以去试件。

这个先说结论吧，我们组内没有，原因可能是因为我们组内的项目基本没有做UI自动化的，都是做接口覆盖，或者coding去测底层框架的，所以不是很强需求

但是事情，因为我以前有对接过一些研究员，和他们请教过

这个事情也能做，需要看看要解决的需要痛点是什么

高效的识别元素？还是通过自然语言自动编写自动化case？还是就想要自动学习生成case？

第一个算是算是比较好实现的，对于后面的2种，都是结合gpt做，但是gpt对于一些中文语义prompt的理解还差点意思，如果技术水平OK，可以探索

首先当然是模型问题，这个需要公司有能力训练出一个适合的模型，后者是找到一个开源的适合的模型，找一个合适的目标检测的模型，然后在获取到大量的UI元素的图片，比如可以通过UI自动化的case中增加截图功能，这样可以把截图裁剪、测评、标注，存为数据集

然后就是拿着数据集调整模型，最后模型可以给出识别到的目标图像的坐标

后面2个，有时候也可以通过我们自己古老的逻辑判断来做，对于app测试来讲，monkey有时候不失为一个好用的探索性测试工具



我也去市场上调研过，收费的比如网易有一款智能自动化平台，他们也是只在图像识别上是采用了AI相关的技术

参考文档：

https://blog.csdn.net/YJT1002/article/details/135532710

https://www.51cto.com/article/783817.html

# 问题18

我看你之前应该已经离职了，那个时候为啥先出来呢

离职的原因主要就一个：

最重要的一点是：我在去年的时候，换过一次项目，当时换项目之前做的是Autolink这个项目，这个项目当时还在一些人工智能的工具应用方面拿过奖，但是由于一些部门组织机构的变化，我们这个项目就直接停止维护了，而今年，又新建了一个team要新做一个工具，暂定由于我在项目从0到1交付这一块算是经验比较丰富，我们老板就让我先去了解了一下，我发现，这个新项目的基本功能和我以前测的Autolink完全一样，就是一个简化板的Autolink，而我手头现在的云监控的日志功能，和手头另一个云审计功能又安全一样了，云审计的研发都直接去请教云监控的日志功能怎么做的， 直接来重复copy

这样的无意义的重复安全不符合我的价值观，没必要在呆下去，我就直接辞职了

我还是喜欢做一些不同的事情，可以是业务的不同、是做的事情的不同，总之，我希望是有意义的，不单单是为了工作而工作



# 问题19

就是如果假设我有幸参加的话，进入到公司的话，我是主要负责哪一块呢。

我还有一个问题想问一下，就是现在这个公司最吸引您当时加入的是哪一点