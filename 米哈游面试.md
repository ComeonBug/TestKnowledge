就是近期这家公司他做的是一个业务项目，还是一个技术底层项目啊。

这个的话也是偏向业务的，只不过它的业务的话是它是相当于一个云厂商，然后他提供一个平台，然后比如说他的一些有一些|公司它没有一些模型，没有什么算力以及框架，这这种的，他就可以在我们这儿购买一个套餐，然后他就可以使用我们商汤提供研发的一些模型，或者是商汤的一些算力资源。然后最近的一个项目是这样的。



# 介绍一下你这个面向C的这个项目，它的一个业务链路是什么样

指标采集流程：

采集（prometheus的exporter、是英伟达的dcgm exporter）——prometheus pull data ——dataops pipline ——support 业务逻辑

采集（自研exporter）-post到pushgw ——prometheus pull data ——dataops pipline ——support 业务逻辑



# 采集是通过什么方式采集的，它的底层逻辑是啥？

prometheus的exporter

1）已发布的exporter：如果要采集服务器指标，就用node exporter、如果采集英伟达芯片的指标，就用dcgm exporter，这里可以拓展一下，就是我们性能测试的时候也是需要监控指标的，比如监控一些中间件的指标，这时候也是按照prometheus的exporter，比如：mysql exporter、redis-exporter、kafka-exporter、rabbitmq-exporter等等

2）自研exporter

3）自采集，post给prometheus

https://zhuanlan.zhihu.com/p/273229856



# 项目里面有涉及到除了数据库之外的哪些中间件

网关中间件nginx、消息中间键kafka、rocketmq

# 有涉及到缓存这一块吗？这个项目里面有用到redis吗？举个相关的功能的例子吗

2个地方用到：

云监控会把所有不同的业务产品是的日志采集起来，加好标签（比如是哪个container产生的，是哪个任务产生的）收集起来的日志（通过k8s、client、kafka等途径）按时间顺序存在logstreamSource中，根据请求把这个请求的日志缓存在logstreamBuffer（redis）中，然后logStreamWindow是一个窗口滑动对象，根据前端传过来的参数滑动窗口，将窗口中的logstream返回给前端



按时计费，主要核心是探活，meter服务对prometheus 的metrics探活，1s探一次，并把存活状态存储到redis中，把计量事件存储在postgres中



#  那假设B站的个人中心，它的数据是从redis获取并渲染在页面上的，嗯，我们基于我写的|说的这个场景，你觉得redis相关的测试点有哪些？

基于网站个人中心数据从Redis获取并渲染在页面上的场景，以下是一些可能的测试场景：

1. **基础功能测试**：
   - 验证个人中心的数据是否能够成功从Redis获取并正确渲染在页面上。

2. **数据一致性测试**：
   - 检查Redis中的数据与数据库中的数据是否一致。

3. **缓存命中率测试**：
   - 统计在一定时间内，个人中心数据从Redis命中和未命中的次数，计算缓存命中率。

4. **并发访问测试**：
   - 模拟高并发访问，测试Redis的响应时间和系统的稳定性。

5. **数据更新实时性测试**：
   - 更新数据库中的个人信息，验证Redis中的数据是否能够及时更新，并且页面是否能够展示最新的数据。

6. **缓存失效测试**：
   - 验证Redis中数据过期失效后，系统是否能够自动从数据库中重新加载数据。

7. **持久化测试**：
   - 如果Redis配置了持久化，测试在Redis重启后，数据是否能够从持久化存储中恢复。

8. **错误注入测试**：
   - 故意引入Redis服务故障，比如网络问题或Redis服务宕机，验证系统的容错和恢复能力。

9. **安全性测试**：
   - 检查是否有可能通过Redis进行未授权的数据访问。

10. **性能测试**：
    - 对Redis进行压力测试，找出性能瓶颈，比如最大连接数、读写速度等。

11. **数据类型和结构测试**：
    - 验证Redis存储的个人中心数据类型（如字符串、列表、集合、散列等）是否正确，以及数据结构是否合理。

12. **键名空间管理测试**：
    - 测试键名空间的管理和监控，确保键名不会产生冲突，并且方便管理和查找。

13. **数据迁移和扩展测试**：
    - 如果需要将数据从一台Redis服务器迁移到另一台，或者扩展集群，测试这一过程是否会对现有服务造成影响。

14. **分布式Redis测试**：
    - 如果使用分布式Redis，测试数据在不同节点之间的同步和一致性。

15. **备份和恢复测试**：
    - 验证Redis数据的备份和恢复机制是否有效。

16. **日志和监控测试**：
    - 检查Redis的日志记录是否完整，监控系统是否能够准确反映Redis的状态。

17. **内存使用测试**：
    - 监控Redis的内存使用情况，确保不会因为内存泄漏导致服务不可用。

18. **连接池测试**：
    - 如果网站使用连接池访问Redis，测试连接池的稳定性和性能。

19. **数据过期策略测试**：
    - 根据个人中心数据的过期策略，验证Redis是否按预期工作。

20. **灾难恢复测试**：
    - 模拟整个Redis集群的故障，验证灾难恢复计划的有效性。

每个测试场景都应该有明确的测试用例和预期结果，以确保Redis在网站个人中心的应用中稳定可靠。



# 前面有提到用过消息中间件这个东西，能说说看这个消息中间件在你的工作里面的使用场景

1、监控kafka中间件：

​	1）pull data阶段：

​		otel 服务通过OpenTelemery collector的receiver收集器组件，对接不同的数据存储端进行数据采集，指标采集的逻辑就是prometheus receiver对prometheus的数据存储端定时做数据刮取操作（比如log的pull data阶段的就是通过kafka receiver采集器进行刮取）

​	2）日志收集后都是推动到了kafka，有3种方式

​		第一种（比如算力池）是通过syslog收集各节点的日志，然后通过filebeat把日志推送到kafka（实例的创建、删除的操作日志是不是通过这种方式呢？）

​		第二种（比如云容器）是将原生日志转化为文件日志，然后Sidecar模式，增加一个logging模块，将日志输出为结构化文件日志，然后通过filebeat把日志推到kafka

​		第三种是子产品（比如裸金属）直接输出结构化文件日志，这时也是通过filebeat推送到kafka

​		概括来说，通过syslog收集日志、通过子产品直接输出日志、通过loggin模块，总之日志最后的格式是结构化文件格式的日志，然后通过已经部署好的filebeat推送到kafka日志存储，然后提取数据到opensearch做日志的持久化

​	3)具体如何滑动窗口的呢？

云监控会把所有不同的业务产品是的日志采集起来，加好标签（比如是哪个container产生的，是哪个任务产生的）收集起来的日志（通过k8s、client、kafka等途径）按时间顺序存在logstreamSource中



​	4）计量功能Billing服务读取postgres存储的计量事件，转化为云管的billing agent，推送到云管的消息队列

​	

# 前面你提到这个审计项目用了MQ这个东西吗？那能不能说说看你曾经有没有遇到过MQ相关的问题，或者你现在会觉得他会有什么问题吗？

使用RocketMQ时可能会遇到的一些问题包括但不限于：

1. **消息丢失**：
   - 在生产、传输或消费过程中，由于网络问题或服务故障，可能会导致消息丢失。

2. **消息重复**：
   - 由于网络波动或客户端重试机制，可能会导致消息被多次发送或消费，从而产生重复消息。

3. **顺序消息处理**：
   - RocketMQ保证顺序消息需要特定的配置，不正确的配置可能导致消息顺序错乱。

4. **高并发压力**：
   - 在高并发场景下，Broker可能会成为瓶颈，导致性能下降。

5. **集群容错和故障转移**：
   - 如果集群配置不当，Broker或NameServer的故障可能会导致消息队列不可用。

6. **消息优先级问题**：
   - RocketMQ不支持消息级别的优先级，这可能不满足一些业务场景的需求。

7. **跨网络传输问题**：
   - 在分布式部署的情况下，跨网络传输可能会增加延迟和丢消息的风险。

8. **资源竞争**：
   - 在大量消息堆积时，消费者可能无法及时处理，导致资源竞争和队列阻塞。

9. **版本兼容性**：
   - 不同版本的RocketMQ可能存在兼容性问题，升级版本时需要谨慎。

10. **运维复杂性**：
    - 随着集群规模的扩大，运维的复杂性也会增加，包括监控、故障排查、性能调优等。

11. **数据倾斜**：
    - 在某些情况下，消息可能会在不同的队列之间分布不均，导致数据倾斜。

12. **配置管理**：
    - 错误的配置可能导致性能问题或消息处理逻辑错误，如Broker的刷盘策略、消费并行度等。

13. **事务消息的复杂性**：
    - 使用事务消息可以提高数据一致性，但同时也增加了编程复杂性。

14. **集群扩展性**：
    - 在业务增长时，需要对RocketMQ集群进行扩容，这可能涉及到复杂的迁移和重新配置。

15. **安全性问题**：
    - 如果未正确配置访问控制和加密，可能会有安全漏洞，如未授权访问或数据泄露。

针对这些问题，需要采取相应的解决方案，如使用事务消息、保证幂等性的消费逻辑、合理配置集群、监控和优化性能等。



使用kafka会出现问题：

是的，Kafka中也存在类似的问题，具体包括：

1. **消息丢失**：
   - Kafka中Broker、Producer和Consumer都可能导致消息丢失。Broker可能会因为未及时将数据从Page Cache刷新到磁盘而丢失数据。Producer在发送消息时，如果未正确处理重试机制，也可能导致消息丢失。Consumer在消费消息后，如果没有正确提交offset，可能会导致消息未被正确处理。

2. **消息重复**：
   - Kafka中的消息重复可能发生在生产者、Broker或消费者三个方面。例如，生产者重试机制在没有正确实现幂等性的情况下可能导致消息重复。

3. **顺序消息处理**：
   - Kafka保证顺序消息需要特定的配置，不正确的配置可能导致消息顺序错乱。

4. **消息堆积**：
   - 如果Consumer消费速度跟不上Producer生产速度，可能会导致消息积压。

5. **消息重复消费**：
   - 在自动提交offset的情况下，如果Consumer在处理消息过程中失败或宕机，可能会造成重复消费。

6. **消费端offset提交问题**：
   - Consumer在自动提交offset时，如果处理未完成就宕机，会导致未处理的消息丢失。因此，可以采用手动提交offset的方式。

7. **生产者确认机制**：
   - Kafka生产者可以通过调整acks参数来确保消息发送的可靠性。例如，设置acks=all可以最大程度保证消息不丢失，但可能影响性能。

8. **JVM参数设置**：
   - Kafka作为运行在JVM上的应用，合理的JVM参数设置对性能有重要影响。例如，选择合适的垃圾收集器和调整堆大小。

针对这些问题，Kafka社区和用户已经提出了多种解决方案，包括调整Kafka配置参数、使用幂等性生产者、优化Consumer的消费逻辑、合理设置JVM参数等。正确应用这些解决方案可以有效减少Kafka中消息丢失和重复的问题。

# 前面你提到会丢消息这件事情，那我们假设你现在所有的项目都按预期的部署完毕了。但是还是会丢消息，这种丢消息的原因可能会有哪些吗？

RocketMQ中消息丢失可能的原因主要包括以下几点：

1. **生产阶段网络问题**：
   - 如果Producer在发送消息给Broker时遇到网络延迟或不可达，消息可能会丢失。

2. **Broker存储问题**：
   - Broker收到消息后，可能先存储在内存中，然后根据刷盘策略持久化到硬盘。如果在持久化过程中Broker异常宕机，可能导致消息丢失。

3. **异步刷盘机制**：
   - RocketMQ默认采用异步刷盘机制，如果Broker在消息未刷盘到磁盘时宕机，消息会丢失。可以通过配置同步刷盘提高数据可靠性，但可能影响性能。

4. **集群复制延迟**：
   - 在集群部署中，如果Master节点在同步数据给Slave节点前宕机，并且消息还未持久化到磁盘，可能导致消息丢失。

5. **消息确认机制**：
   - 如果消息发送后未得到正确的确认，可能会导致消息未被正确处理而丢失。

6. **消费阶段问题**：
   - 消费者在成功获取消息后，如果在业务逻辑处理完成前宕机，并且已经确认消息消费完成，消息可能会丢失。

7. **消息重试机制**：
   - 如果消息消费失败并且没有正确实现重试逻辑，消息可能会丢失。

8. **Topic队列配置问题**：
   - 错误的Topic队列配置可能导致消息写入和读取的队列不一致，从而导致消息丢失。

9. **Producer发送失败处理**：
   - 如果Producer在发送消息失败后没有实现失败重试或者失败记录，消息可能会丢失。

10. **消费者负载不均衡**：
    - 如果消费者组之间的消息负载不均衡，可能导致某些消息未被消费。

为了减少消息丢失的风险，可以采取以下措施：

- 使用同步发送而非单向发送，确保消息发送结果被确认。
- 配置同步刷盘策略，确保消息持久化到磁盘。
- 实现集群部署和主从复制，提高消息存储的可靠性。
- 确保消费者正确处理消息并完成确认。
- 实现消息发送和消费的失败重试机制。
- 正确配置Topic的读写队列，避免消息写入和读取的队列不一致。

通过这些措施，可以显著降低RocketMQ中消息丢失的风险。



# 那如果按你前面举的几个例子中，如果现在消息丢了，有什么好的补救措施？

在RocketMQ中，消费端可能因为多种原因没有消费到消息，以下是一些可能导致此问题的程序bug类型：

1. **消息监听器异常处理不当**：
   - 如果消费端在处理消息时抛出了未捕获的异常，可能会导致消费线程中断，从而无法继续消费消息。

2. **消费端配置错误**：
   - 错误的消费组名、Topic订阅信息或其他配置问题可能导致消费者无法从Broker获取消息。

3. **网络问题**：
   - 网络抖动或通信异常可能导致消费者与Broker之间的连接中断，从而无法消费消息。

4. **Broker宕机或集群故障**：
   - 如果Broker宕机或集群出现故障，消费者可能无法从Broker拉取消息。

5. **消息队列和消费队列不匹配**：
   - 如果消费者指定的消息队列与实际发送消息的队列不一致，将无法消费到消息。

6. **消费策略不当**：
   - 如重试策略设置不当，可能导致消费失败的消息无法正确重试或延迟重试。

7. **事务消息处理不当**：
   - 事务消息需要正确处理事务状态，否则可能导致消息无法被正常消费。

8. **消费者负载不均衡**：
   - 如果消费者之间的负载不均衡，部分消费者可能会消费大量消息，而其他消费者则消费很少或没有消息。

9. **消息过滤逻辑错误**：
   - 消费者可能因为消息过滤标签或SQL语法错误，而无法匹配到任何消息。

10. **消费者权限问题**：
    - 消费者可能因为缺少访问Topic的权限而无法消费消息。

11. **消费者内部错误**：
    - 消费者内部的bug，如资源管理不当、状态机错误等，也可能导致消息消费失败。

12. **消息顺序问题**：
    - 如果消息依赖特定的顺序，但消费者没有按顺序消费，可能会导致业务逻辑错误，从而影响消息的消费。

13. **消费者超时设置不当**：
    - 如果消费者拉取消息的超时时间设置过短，可能在高负载情况下导致消费者无法及时获取消息。

14. **版本兼容性问题**：
    - 如果客户端和服务端RocketMQ版本不兼容，可能会出现消费者无法消费消息的问题。

解决这些问题通常需要对RocketMQ的日志进行详细分析，检查消费者的状态和配置，以及确保整个系统的稳定性和网络环境的可靠性。在某些情况下，可能还需要对RocketMQ的源码进行调试，以便找到并修复bug。

# 接下来会问一个排错题，假设你现在在一个web端上传图片，点击提交的那一瞬间报了系统异常四个字。你会根据什么工具或方式来定位这次根本原因是什么？

F12——response信息判断前后端问题

后端去服务器看error log，直接ssh到服务器上去看，linux命令即可

然后去对应的服务去看error log，也是直接服务所在机器或者pod上去看日志，先看所在机器和pod的日志，状态，再看服务的日志和状态





# 接下来会问一些web端的问题，我们其实会有很多端，Web端、小程序、APP对端，那么你能说说看web端它与众不同的点。或者你觉得他有意思的特性有哪些吗？





# 那web里面它一般会用到cookie和session, 那说说看这俩区别是什么？

嗯，Cookie的话一般存到本地吧，Session一般存到服务器端，然后他们都是一些就是其实是一些认证啊，校验相关的东西，然后cookie的话存到本地之后，嗯。然后H我们的请求头里面一般传的都是cookie，然后所以的话，这个cookie就，很多时候就让我们做自动化的话，它你获取到一次投N。A cookie token, 嗯。哦，Cookie.哦，一样。嗯，就是，然后这个cookie的话，可能就是你根据他可能会升就是。我我们的一些安全，安全措施里|里面会有一些cookie的，嗯，那叫什么来着，Cook cookie盗用。对，然后就是你拿到本地的cookie之后，然后放到你的请求里面，因为请求头也有cookie这个信息，然后你就可以直接仿造这个人去操作嘛。然后，这块的话就是。但是cookie它的失会有一些一定就是一定时间内就会容易失效，嗯，所以需要就是再次去请求一个cookie，然后session的话，它就是放在服务端的一个也是，其实这俩都是为了不要让用户。每次都去请，就是。相当于一个新新的请求，重新调重新去校验啊，重新去验证这一套，所以他们都是为了那个，嗯。在我看来有点类似于像缓存这样|靠一个逻辑啊，但是他们确实不一样，然后session的话就是放在服务端的。嗯，一个缓存，嗯。Session的session机制，嗯。Session的机制的话。我想想怎么描述一下。嗯，Session的话，它对比cookie，它失效的时间可能会更长，而且它有一个配对校验的机制。嗯，我想，嗯。这块我去先这块不咋熟了就。

# 简历里面有看到过做过一些自动化相关的工作，那能不能说说看你的接口自动化是怎么做的吗？

接口对，然后，接口这边的话就是。我反正|就是做过反一般，嗯，我现在在我们这家单位就光接口测试就做过两套，给就是两套的定制化框架，然后总结过来的话就是它其实底层的框架，底层我们的设计方式是一样的，就是底层它设及到的模块就是那几块，嗯，一块是data塔存的一些数据，然后这个数据的话，可能是你的测试用例的数据，也可能是一些你的解析后的数据，总之是data层，然后还有是YouTube层，就是一些工具类的包，然后还有是你的test case, 哦，最后是report，然后最后最外层会有一些comfort复的配置文件，Inn的配置文件和可能会有一些main函数的入口，然后它的框架就是大的框架，就这几个，然后具体的话可能根据你的项目不同，然后还有你的可能还有一些人员水平|和技术人员的水平不同，还有是你的，比如说他的业务方向不同，也是会。导致你设计方式不一样的，然后具体的设计方式不同，其实它不同在的是比如说data层，你是怎么去做一个数据的。有点像数据采集啊，就是怎么去管理测试用例的，有一些团队可能是杨mmy Jason就管理了，有一些团队他可能需要提供一些Excel文件，然后让一些技术不太不那么好的同学，然后在Excel里面去编写一些，嗯，编写一些就是内容case，然后作为一个输入。然后这是一个，比如说这是这种不同，然后，其中还有一些比如说解析的不同，嗯，这个同这块不用延伸，我问几个问题，就这个框来是你自己搭的，

# 那能告诉我你是通过什么方式驱动这个自动化的吗|什么方式驱动

你是说设计模式吗？不是，比如说我要执行这个自动化，你本地点一下也是执行，我们是通过那个jenkins，然后它是集成到了一个CICD流程里面的。

# 那能说要看你设计用力的一个方向是怎么设计的吗？嗯，做自动化的这个用力设计方向好的

能解决当前问题的自动化设计就是好的设计

可以简单可以复杂，只要能够解决当前测试通过需要自动化的事项，就是好的设计



#  那你执行完了以后，通过什么判断来判定你这次case是好与坏，就是成功与否是吗？

我认为是一个case结果的有效性

如果这个case执行完了，你能放心的说这个功能没问题，那就是好的

所以，我在断言上的设计会更加丰富和严格

但是这是一个很个人的思想，每个团队每个人理解不同，而且case by case，不同的需求下也是需要不同的设计的

# 你觉得一个好的段应该怎么设计|一个好的断言怎么去设计？



在自动化测试中，断言（Assertion）是用来验证测试结果是否符合预期的一种机制。一个良好的断言实践对于确保测试的有效性和准确性至关重要。以下是一些在自动化测试中做好断言的技巧和最佳实践：

1. **明确预期结果**：
   在编写测试之前，明确知道每个测试案例应该达到的预期结果。

2. **使用有意义的断言**：
   避免使用通用的断言，如“不为null”，而应该使用更具体的断言来描述预期的行为。

3. **使用断言库**：
   大多数测试框架都提供了丰富的断言库，使用这些库可以提高断言的可读性和表达力。

4. **提供有用的失败信息**：
   当断言失败时，提供有用的错误信息，这有助于快速定位问题。

5. **使用软断言**：
   在某些情况下，使用软断言（软断言允许测试在断言失败后继续执行）来收集更多的失败信息。

6. **避免过度断言**：
   不要在一个测试中做太多的断言，这会使测试变得难以管理和维护。

7. **使用参数化断言**：
   当需要对一系列值进行断言时，使用参数化断言可以减少重复代码。

8. **断言异常**：
   如果测试是验证某个操作应该抛出异常，使用专门的断言来检查异常类型和消息。

9. **使用断言分组**：
   对于复杂的断言，可以将它们分组为逻辑块，以提高可读性。

10. **检查非行为结果**：
    除了检查方法的返回值，还应该检查方法的副作用，如状态变化、数据库更新等。

11. **使用匹配器或哈姆雷特**：
    对于复杂的数据结构，使用匹配器（Matchers）或哈姆雷特（Hamcrest）库来编写更灵活的断言。

12. **断言日志和消息**：
    验证系统产生的日志和消息是否符合预期。

13. **断言性能指标**：
    对于性能测试，断言响应时间、吞吐量等性能指标是否在可接受范围内。

14. **使用可视化断言**：
    对于UI测试，使用视觉回归测试工具来断言UI的变化。

15. **持续集成中的断言**：
    在CI/CD流程中，确保断言能够正确地失败测试并提供反馈。

16. **断言数据的一致性**：
    验证数据在不同系统或服务之间的一致性。

17. **编写可维护的断言**：
    断言代码应该易于理解和维护。

18. **理解断言的局限性**：
    了解断言不能验证的内容，如用户体验或业务逻辑的某些方面。

19. **断言安全相关的特性**：
    对于需要验证的安全特性，如认证和授权，使用适当的断言来检查安全行为。

20. **使用行为驱动开发（BDD）**：
    使用BDD框架（如Cucumber）来定义断言，它们允许使用自然语言来描述预期行为。

通过遵循这些最佳实践，可以编写出更加健壮、可读和可维护的自动化测试断言，从而提高测试的质量和效率。



在接口测试自动化中，断言（Assertion）是用来验证测试结果是否符合预期的关键环节。良好的断言设计可以帮助团队更准确地捕捉到问题，并且提供有用的反馈。以下是一些设计断言的最佳实践：

1. **使用明确的断言**：避免使用过于笼统的断言，如断言整个响应体相等。应该针对预期验证点进行断言，比如状态码、响应头、具体字段值等。

2. **断言关键响应数据**：确保对那些对业务逻辑至关重要的响应字段进行断言，如订单号、用户ID、状态信息等。

3. **状态码断言**：对HTTP状态码进行断言，以确保请求的结果是成功或预期的失败。

4. **响应时间断言**：对于性能敏感的接口，可以断言响应时间是否在可接受的范围内。

5. **使用通配断言**：对于某些无法预知具体值但知道其模式的响应数据，可以使用正则表达式或通配符进行断言。

6. **多条件组合断言**：使用逻辑运算符组合多个断言条件，以验证复杂的情况。

7. **避免过度断言**：不要在一个测试中塞入太多的断言，这会使得测试过于脆弱且难以维护。应该将测试分解成更小的单元。

8. **断言异常处理**：对于预期会产生异常或错误的接口调用，应该断言系统是否返回了正确的错误信息和状态码。

9. **使用断言库**：利用测试框架提供的断言库，如pytest的`assert`语句，可以提供更丰富的断言功能和更好的错误消息。

10. **响应体结构断言**：如果响应体是JSON或XML格式，断言其结构是否符合预期的schema。

11. **非严格断言**：在某些情况下，如果响应体的顺序或一些非关键字段不重要，可以使用非严格比较。

12. **记录和日志**：当断言失败时，提供足够的日志和记录，以便于调试。

13. **参数化断言**：对于使用相同逻辑但不同参数的断言，可以设计参数化的测试用例。

14. **软断言**：在某些情况下，可以使用软断言来记录多个断言失败，而不是使整个测试用例立即失败。

15. **自定义断言**：根据需要编写自定义断言函数，以复用常见断言逻辑。

16. **断言重试机制**：对于可能由于临时网络或其他不稳定因素导致断言失败的情况，可以设计重试机制。

17. **监控和警报**：将断言结果与监控系统结合，当断言失败时触发警报。

18. **文档和注释**：为断言逻辑提供清晰的文档和注释，帮助团队成员理解预期行为。

通过这些方法，可以设计出更加健壮、清晰和有用的断言，提高接口测试自动化的效率和有效性。

你只会去断言返回结果里的东西，然后把返回的东西拆成了几个exception对应的美句

不止可以断言返回结果的东西，还可以断言返回结果的时长、

# 前面你说过做过性能测试相关的工作，那能分享一下那些|这是怎么做的了？

性能测试流程：

1. 需求分析

2. 制定性能测试计划和方案（看做啥子类型的性能测试，测试场景定下，预期的一个目标是啥），以及进行方案评审

   - 基准测试：单接口基准测试，是为了在没有压力的情况下做摸底测试，基准测试都不过的话，就没有必要走下面的流程

   - 负载测试：找拐点

   - 压力测试

   - 稳定性测试

   - 极限测试

   - 浪涌测试（打满-释放-打满-释放）

   - 配置测试  

3. 准备
   - 环境设计
   - 硬件环境
   - 软件环境
   - 部署服务
   - 待测接口列表
   - 测试数据准备
     - 旧数据来源是运维、运营、产品
     - 新数据来源是预估
4. 执行
   - 脚本生成，调通
   - 脚本增强：
     - 提取变量
     - token配置
     - 等待时间
     - 提取公共参数
     - 参数化
   - case场景搭建
     - 集合点：Sleeping_Thread_Group
     - 定时器
     - 控制器
       - 事物控制器
       - 仅一次控制器
       - 吞吐量控制器
   - 搭建指标监控
   - 执行case：确认下面点，确保流量真正打到了被压测的服务器上
     - 网络最大带宽
     - 是否有单ip地址限制
     - slb自动伸缩是否生效
     - nginx负载均衡是否生效
     - nginx机器性能是否受限
     - 是否有限流、熔断、降级策略
     - 施压机是否本身有机器性能瓶颈
   - 输出结果
5. 调优
   - 调优
   - 执行case
   - 输出结果
   - 调优
   - ....
6. 报告与总结
   - 概述：目的、背景、需求、名词解释
   - 概要：测试环境、工具及版本、人员情况
   - 测试方案：数据准备、场景设计、脚本准备、环境部署脚本
   - 调优过程：出问题的场景、图、数据、优化方案、优化前后对比
   - 测试结果和分析：压测数据、图表、结论



# 那我换一个问法，嗯，我会把一组数据发到公屏上，然后你来告诉我他会有哪些问题，

好的。能看到这组数据了，10 100 20 200 30 220 40 225，OK.左边是线程数，右边是QPS，

一般来说他们是一个正比关系，但是这张图的话，2030时就不那么正常了，那么根据你的经验来告诉我，会有哪些因素导致他这样？

左边是啊。你好，那个左边是线程数，线程数左边是QPS。QPS, 哦，什么样导致这样的一个问题|嗯。嗯，他这个很明显是在。30~40之间，它已经到到了一个瓶颈，但是一般的话，我们分析瓶颈的话，不是看不是看这个拐点，而他应该其实在前面就已经有问题了，所以我们可能排查20~30，它定位20~30那里其实就已经有一些问题，哎。哎，不对，20~30是拐点，OK, 然后，那可能在把这个。先要再把这个细分嘛，从20~30，你可可能要再小一点，嗯。20~30这么小就出问题，如果如果再扩大一点啊，如果是稍微扩大一点，然后的话，那种时候就可以再逐步缩小这个范围，看一下到底它的性能拐点是在哪里。嗯，然后出现这个|这个问题。200。

# 你可以理解，你现在就是这么压的，然后压出来的结果就是这样的结果。所以能告诉我是哪些因素导致的吗？

本地机器压测可能会有的问题：

1、本地机器的资源限制：cpu、mem、磁盘IO，可能会本地资源耗尽，不足以模拟真正的高并发

2、网络带宽

3、服务器限流或者安全限制



# 最后一个问题是一个用例设计器。有一个商城系统，它是可以通过虚拟币支付的。支付成功之后，用户会收到一条动账的消息。那么基于这个背景，你来设计一下测试点。

哦，商城啊，我我稍微记一下，不好意思，嗯，就是它是一个商城给他发错了。商城系统可以通过虚拟币支付，支付成功后会收到动账的消息。然后设计设计测试用力是吧。测试点就可以测试点。OK.好的，然后|先如果我拿到这个需求的话，哦，先先就是去分析一下其中主要的测试的一个点在哪里，比如说这样这个需求来说的话，他通过虚拟币支付，这是一个点，就是它看就是其他的支付方式是不OK的，虚拟币是OK的。然后就是它的可能是一个调用的一个支付方式吧，只能调调起这个虚拟币啊，这个以及或者展示只有虚拟币这种，然后支付成功之后，然后根据支付成功这句话的话，可能再拆分出的消息是，比如说支付成功是一个，那支付不成功是什么？这块的话，可能是需求需要再补充全面不成功呢。到时候系统的的一些表现是什么。然后对于支付成功的话。会收到动账的消息，他需求里面是收到动账的消息通知|然后这里的话是。消息通知是收到的，然后再确认消息通知里面的信息是OK的，以及当然首先要去确认的是他的这个个人的账户里面。就是后台，就是我们可能去数据库里面去查他的数据变更是正确的。嗯。就会成功，OK, 然后这里的话，嗯。支付成功，OK, 然后。我不确定这个消消息币，它对于比如说他到账之后后后期的一个消费的一个影响，或者是他能不能当即消费或者之类的，这是后续的一个事情啊，然后目前看这块儿的话就是。正向流程，就是我刚所说的。现支付成功的这一套流程，然后异常的情况的话，需要产品补充|赔偿的一个需求就是支付不成功的情况。目前看的话。嗯。哎呀。嗯。大概主要也就这2。嗯，这些吧。这个不可成功的场景能再拆的更细一点吗？会因有哪些因素或原因导致它不成功，然后把它转成测试点，嗯。嗯，支付成功的一个校验的话，嗯，校验点的话就是首先是他的账户变更正确，账户的余额变更正确，然后还有是他的。它的一个消息收，消息发送正确，然后还有是消息体正确。嗯。然后支付不成功的话，有可能是比如说用户主动取消支付|嗯，然后还有是可能，嗯。他的支，比如说余额不足这种的就是它的非异常情况，是业务流程的异常。比如说余额不足，或者是。嗯。然后或者是一个什么呢。嗯，然后一还有一些可能是一些比如说网络，比如说国国内网络，它有一些无法无法这种操作的一些。嗯，还会有一些可能通过一些工具去模拟一下。落网啊，或者是什么的情况，嗯。不成功的话，其实也可以去模拟一下，比如说我们|服务服务器就是宕机的情况，他确实他再去支付了，这种情况就是我们服务本身的异常。

# 那我的问题问完了，有什么想问我的吗？

因为我们现在因为测试这个块，他可能很多是有些是做业务项的，又是做基建项的，那那其实面向的技能可能会不太一样，但对业务项的同学来说，可能更多的是要把自己的产品，相当于在给人说的时候，就是类似于销售的一个角色，就是把这个东西想办法卖给你，让你足够的了解。来。对于介绍自己项目的时候，其实可以更多的把自己站在一个销售的角度，让这边更多的能了解你会从业用户的一个角度。但是足够的感受到你这个|的项目获取产品啊，项样你是怎么使用的，这是一个业务上的一个角。另外横向的角度的话，其实就是一个技能的一个使用啊，可能就是。我们可能其实并不需要展示，就是掌握很多很多技术站，因为技术本来就是一直在更新迭代的，所以更多的是通过解决问题的角度来选择我们更适合的一些技术站。